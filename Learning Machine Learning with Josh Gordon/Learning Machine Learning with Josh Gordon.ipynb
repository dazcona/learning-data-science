{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Machine Learning with Josh Gordon\n",
    "\n",
    "Awesome videos from the Google Developers channel on Youtube:\n",
    "\n",
    "https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal\n",
    "\n",
    "and his github and twitter channels:\n",
    "\n",
    "https://github.com/random-forests/\n",
    "\n",
    "https://twitter.com/random_forests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Hello World - Machine Learning Recipes\n",
    "\n",
    "Machine Learning as a subfield of Artificial Intelligence.\n",
    "\n",
    "LEARN FROM EXAMPLES AND EXPERIENCE\n",
    "- Machine Learning is the study of algorithms that learn from examples and experience instead of relying on hard-coded rules.\n",
    "\n",
    "Can you write code to tell the difference between an apple and an orange?\n",
    "\n",
    "TRAIN A CLASSIFIER\n",
    "- A classifier is a function that takes some data as input and assigns a label to it as output\n",
    "\n",
    "SUPERVISED LEARNING\n",
    "- Create a classifier by finding patterns in examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    [140, \"smooth\"],\n",
    "    [130, \"smooth\"],\n",
    "    [150, \"bumpy\"],\n",
    "    [170, \"bumpy\"]\n",
    "]\n",
    "labels = [\"apple\", \"apple\", \"orange\", \"orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    [140, 1],\n",
    "    [130, 1],\n",
    "    [150, 0],\n",
    "    [170, 0]\n",
    "]\n",
    "labels = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(features, labels) # find patterns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fruit = [160, 0]\n",
    "clf.predict([new_fruit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualizing a Decision Tree - Machine Learning Recipes\n",
    "\n",
    "Many types of classifiers:\n",
    "- Artificial neural network\n",
    "- Support Vector Machine\n",
    "- etc\n",
    "\n",
    "By using Decision Trees, we can visualize how they work!\n",
    "\n",
    "IRIS DATASET\n",
    "- Import dataset\n",
    "- Train a classifier\n",
    "- Predict label for new flower\n",
    "- Visualize the tree\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print iris.feature_names\n",
    "print iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1,  3.5,  1.4,  0.2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The features and examples are contained in the data variable\n",
    "iris.data[0]\n",
    "# measurements for the first flower\n",
    "# sepal length, sepal width, petal length, petal width as the feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target[0]\n",
    "# label of 0 means setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 0: label 0, features [ 5.1  3.5  1.4  0.2]\n",
      "Example: 1: label 0, features [ 4.9  3.   1.4  0.2]\n",
      "Example: 2: label 0, features [ 4.7  3.2  1.3  0.2]\n",
      "Example: 3: label 0, features [ 4.6  3.1  1.5  0.2]\n",
      "Example: 4: label 0, features [ 5.   3.6  1.4  0.2]\n",
      "Example: 5: label 0, features [ 5.4  3.9  1.7  0.4]\n",
      "Example: 6: label 0, features [ 4.6  3.4  1.4  0.3]\n",
      "Example: 7: label 0, features [ 5.   3.4  1.5  0.2]\n",
      "Example: 8: label 0, features [ 4.4  2.9  1.4  0.2]\n",
      "Example: 9: label 0, features [ 4.9  3.1  1.5  0.1]\n",
      "Example: 10: label 0, features [ 5.4  3.7  1.5  0.2]\n",
      "Example: 11: label 0, features [ 4.8  3.4  1.6  0.2]\n",
      "Example: 12: label 0, features [ 4.8  3.   1.4  0.1]\n",
      "Example: 13: label 0, features [ 4.3  3.   1.1  0.1]\n",
      "Example: 14: label 0, features [ 5.8  4.   1.2  0.2]\n",
      "Example: 15: label 0, features [ 5.7  4.4  1.5  0.4]\n",
      "Example: 16: label 0, features [ 5.4  3.9  1.3  0.4]\n",
      "Example: 17: label 0, features [ 5.1  3.5  1.4  0.3]\n",
      "Example: 18: label 0, features [ 5.7  3.8  1.7  0.3]\n",
      "Example: 19: label 0, features [ 5.1  3.8  1.5  0.3]\n",
      "Example: 20: label 0, features [ 5.4  3.4  1.7  0.2]\n",
      "Example: 21: label 0, features [ 5.1  3.7  1.5  0.4]\n",
      "Example: 22: label 0, features [ 4.6  3.6  1.   0.2]\n",
      "Example: 23: label 0, features [ 5.1  3.3  1.7  0.5]\n",
      "Example: 24: label 0, features [ 4.8  3.4  1.9  0.2]\n",
      "Example: 25: label 0, features [ 5.   3.   1.6  0.2]\n",
      "Example: 26: label 0, features [ 5.   3.4  1.6  0.4]\n",
      "Example: 27: label 0, features [ 5.2  3.5  1.5  0.2]\n",
      "Example: 28: label 0, features [ 5.2  3.4  1.4  0.2]\n",
      "Example: 29: label 0, features [ 4.7  3.2  1.6  0.2]\n",
      "Example: 30: label 0, features [ 4.8  3.1  1.6  0.2]\n",
      "Example: 31: label 0, features [ 5.4  3.4  1.5  0.4]\n",
      "Example: 32: label 0, features [ 5.2  4.1  1.5  0.1]\n",
      "Example: 33: label 0, features [ 5.5  4.2  1.4  0.2]\n",
      "Example: 34: label 0, features [ 4.9  3.1  1.5  0.1]\n",
      "Example: 35: label 0, features [ 5.   3.2  1.2  0.2]\n",
      "Example: 36: label 0, features [ 5.5  3.5  1.3  0.2]\n",
      "Example: 37: label 0, features [ 4.9  3.1  1.5  0.1]\n",
      "Example: 38: label 0, features [ 4.4  3.   1.3  0.2]\n",
      "Example: 39: label 0, features [ 5.1  3.4  1.5  0.2]\n",
      "Example: 40: label 0, features [ 5.   3.5  1.3  0.3]\n",
      "Example: 41: label 0, features [ 4.5  2.3  1.3  0.3]\n",
      "Example: 42: label 0, features [ 4.4  3.2  1.3  0.2]\n",
      "Example: 43: label 0, features [ 5.   3.5  1.6  0.6]\n",
      "Example: 44: label 0, features [ 5.1  3.8  1.9  0.4]\n",
      "Example: 45: label 0, features [ 4.8  3.   1.4  0.3]\n",
      "Example: 46: label 0, features [ 5.1  3.8  1.6  0.2]\n",
      "Example: 47: label 0, features [ 4.6  3.2  1.4  0.2]\n",
      "Example: 48: label 0, features [ 5.3  3.7  1.5  0.2]\n",
      "Example: 49: label 0, features [ 5.   3.3  1.4  0.2]\n",
      "Example: 50: label 1, features [ 7.   3.2  4.7  1.4]\n",
      "Example: 51: label 1, features [ 6.4  3.2  4.5  1.5]\n",
      "Example: 52: label 1, features [ 6.9  3.1  4.9  1.5]\n",
      "Example: 53: label 1, features [ 5.5  2.3  4.   1.3]\n",
      "Example: 54: label 1, features [ 6.5  2.8  4.6  1.5]\n",
      "Example: 55: label 1, features [ 5.7  2.8  4.5  1.3]\n",
      "Example: 56: label 1, features [ 6.3  3.3  4.7  1.6]\n",
      "Example: 57: label 1, features [ 4.9  2.4  3.3  1. ]\n",
      "Example: 58: label 1, features [ 6.6  2.9  4.6  1.3]\n",
      "Example: 59: label 1, features [ 5.2  2.7  3.9  1.4]\n",
      "Example: 60: label 1, features [ 5.   2.   3.5  1. ]\n",
      "Example: 61: label 1, features [ 5.9  3.   4.2  1.5]\n",
      "Example: 62: label 1, features [ 6.   2.2  4.   1. ]\n",
      "Example: 63: label 1, features [ 6.1  2.9  4.7  1.4]\n",
      "Example: 64: label 1, features [ 5.6  2.9  3.6  1.3]\n",
      "Example: 65: label 1, features [ 6.7  3.1  4.4  1.4]\n",
      "Example: 66: label 1, features [ 5.6  3.   4.5  1.5]\n",
      "Example: 67: label 1, features [ 5.8  2.7  4.1  1. ]\n",
      "Example: 68: label 1, features [ 6.2  2.2  4.5  1.5]\n",
      "Example: 69: label 1, features [ 5.6  2.5  3.9  1.1]\n",
      "Example: 70: label 1, features [ 5.9  3.2  4.8  1.8]\n",
      "Example: 71: label 1, features [ 6.1  2.8  4.   1.3]\n",
      "Example: 72: label 1, features [ 6.3  2.5  4.9  1.5]\n",
      "Example: 73: label 1, features [ 6.1  2.8  4.7  1.2]\n",
      "Example: 74: label 1, features [ 6.4  2.9  4.3  1.3]\n",
      "Example: 75: label 1, features [ 6.6  3.   4.4  1.4]\n",
      "Example: 76: label 1, features [ 6.8  2.8  4.8  1.4]\n",
      "Example: 77: label 1, features [ 6.7  3.   5.   1.7]\n",
      "Example: 78: label 1, features [ 6.   2.9  4.5  1.5]\n",
      "Example: 79: label 1, features [ 5.7  2.6  3.5  1. ]\n",
      "Example: 80: label 1, features [ 5.5  2.4  3.8  1.1]\n",
      "Example: 81: label 1, features [ 5.5  2.4  3.7  1. ]\n",
      "Example: 82: label 1, features [ 5.8  2.7  3.9  1.2]\n",
      "Example: 83: label 1, features [ 6.   2.7  5.1  1.6]\n",
      "Example: 84: label 1, features [ 5.4  3.   4.5  1.5]\n",
      "Example: 85: label 1, features [ 6.   3.4  4.5  1.6]\n",
      "Example: 86: label 1, features [ 6.7  3.1  4.7  1.5]\n",
      "Example: 87: label 1, features [ 6.3  2.3  4.4  1.3]\n",
      "Example: 88: label 1, features [ 5.6  3.   4.1  1.3]\n",
      "Example: 89: label 1, features [ 5.5  2.5  4.   1.3]\n",
      "Example: 90: label 1, features [ 5.5  2.6  4.4  1.2]\n",
      "Example: 91: label 1, features [ 6.1  3.   4.6  1.4]\n",
      "Example: 92: label 1, features [ 5.8  2.6  4.   1.2]\n",
      "Example: 93: label 1, features [ 5.   2.3  3.3  1. ]\n",
      "Example: 94: label 1, features [ 5.6  2.7  4.2  1.3]\n",
      "Example: 95: label 1, features [ 5.7  3.   4.2  1.2]\n",
      "Example: 96: label 1, features [ 5.7  2.9  4.2  1.3]\n",
      "Example: 97: label 1, features [ 6.2  2.9  4.3  1.3]\n",
      "Example: 98: label 1, features [ 5.1  2.5  3.   1.1]\n",
      "Example: 99: label 1, features [ 5.7  2.8  4.1  1.3]\n",
      "Example: 100: label 2, features [ 6.3  3.3  6.   2.5]\n",
      "Example: 101: label 2, features [ 5.8  2.7  5.1  1.9]\n",
      "Example: 102: label 2, features [ 7.1  3.   5.9  2.1]\n",
      "Example: 103: label 2, features [ 6.3  2.9  5.6  1.8]\n",
      "Example: 104: label 2, features [ 6.5  3.   5.8  2.2]\n",
      "Example: 105: label 2, features [ 7.6  3.   6.6  2.1]\n",
      "Example: 106: label 2, features [ 4.9  2.5  4.5  1.7]\n",
      "Example: 107: label 2, features [ 7.3  2.9  6.3  1.8]\n",
      "Example: 108: label 2, features [ 6.7  2.5  5.8  1.8]\n",
      "Example: 109: label 2, features [ 7.2  3.6  6.1  2.5]\n",
      "Example: 110: label 2, features [ 6.5  3.2  5.1  2. ]\n",
      "Example: 111: label 2, features [ 6.4  2.7  5.3  1.9]\n",
      "Example: 112: label 2, features [ 6.8  3.   5.5  2.1]\n",
      "Example: 113: label 2, features [ 5.7  2.5  5.   2. ]\n",
      "Example: 114: label 2, features [ 5.8  2.8  5.1  2.4]\n",
      "Example: 115: label 2, features [ 6.4  3.2  5.3  2.3]\n",
      "Example: 116: label 2, features [ 6.5  3.   5.5  1.8]\n",
      "Example: 117: label 2, features [ 7.7  3.8  6.7  2.2]\n",
      "Example: 118: label 2, features [ 7.7  2.6  6.9  2.3]\n",
      "Example: 119: label 2, features [ 6.   2.2  5.   1.5]\n",
      "Example: 120: label 2, features [ 6.9  3.2  5.7  2.3]\n",
      "Example: 121: label 2, features [ 5.6  2.8  4.9  2. ]\n",
      "Example: 122: label 2, features [ 7.7  2.8  6.7  2. ]\n",
      "Example: 123: label 2, features [ 6.3  2.7  4.9  1.8]\n",
      "Example: 124: label 2, features [ 6.7  3.3  5.7  2.1]\n",
      "Example: 125: label 2, features [ 7.2  3.2  6.   1.8]\n",
      "Example: 126: label 2, features [ 6.2  2.8  4.8  1.8]\n",
      "Example: 127: label 2, features [ 6.1  3.   4.9  1.8]\n",
      "Example: 128: label 2, features [ 6.4  2.8  5.6  2.1]\n",
      "Example: 129: label 2, features [ 7.2  3.   5.8  1.6]\n",
      "Example: 130: label 2, features [ 7.4  2.8  6.1  1.9]\n",
      "Example: 131: label 2, features [ 7.9  3.8  6.4  2. ]\n",
      "Example: 132: label 2, features [ 6.4  2.8  5.6  2.2]\n",
      "Example: 133: label 2, features [ 6.3  2.8  5.1  1.5]\n",
      "Example: 134: label 2, features [ 6.1  2.6  5.6  1.4]\n",
      "Example: 135: label 2, features [ 7.7  3.   6.1  2.3]\n",
      "Example: 136: label 2, features [ 6.3  3.4  5.6  2.4]\n",
      "Example: 137: label 2, features [ 6.4  3.1  5.5  1.8]\n",
      "Example: 138: label 2, features [ 6.   3.   4.8  1.8]\n",
      "Example: 139: label 2, features [ 6.9  3.1  5.4  2.1]\n",
      "Example: 140: label 2, features [ 6.7  3.1  5.6  2.4]\n",
      "Example: 141: label 2, features [ 6.9  3.1  5.1  2.3]\n",
      "Example: 142: label 2, features [ 5.8  2.7  5.1  1.9]\n",
      "Example: 143: label 2, features [ 6.8  3.2  5.9  2.3]\n",
      "Example: 144: label 2, features [ 6.7  3.3  5.7  2.5]\n",
      "Example: 145: label 2, features [ 6.7  3.   5.2  2.3]\n",
      "Example: 146: label 2, features [ 6.3  2.5  5.   1.9]\n",
      "Example: 147: label 2, features [ 6.5  3.   5.2  2. ]\n",
      "Example: 148: label 2, features [ 6.2  3.4  5.4  2.3]\n",
      "Example: 149: label 2, features [ 5.9  3.   5.1  1.8]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(iris.target)):\n",
    "    print \"Example: %d: label %s, features %s\" %(i, iris.target[i], iris.data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING DATA\n",
    "- Examples used to \"test\" the classifier's accuracy\n",
    "- Not part of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing data\n",
    "# Remove one example from each type of flower\n",
    "# Recall data is ordered\n",
    "test_idx = [0, 50, 100]\n",
    "\n",
    "# training data\n",
    "train_target = np.delete(iris.target, test_idx)\n",
    "train_data = np.delete(iris.data, test_idx, axis=0)\n",
    "\n",
    "# testing data\n",
    "test_target = iris.target[test_idx]\n",
    "test_data = iris.data[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print test_target # labels we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_data) # predicted labels match the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"883pt\" height=\"642pt\"\n",
       " viewBox=\"0.00 0.00 882.83 642.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 638)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-638 878.831,-638 878.831,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.609,-634C522.609,-634 397.146,-634 397.146,-634 391.146,-634 385.146,-628 385.146,-622 385.146,-622 385.146,-568 385.146,-568 385.146,-562 391.146,-556 397.146,-556 397.146,-556 522.609,-556 522.609,-556 528.609,-556 534.609,-562 534.609,-568 534.609,-568 534.609,-622 534.609,-622 534.609,-628 528.609,-634 522.609,-634\"/>\n",
       "<text text-anchor=\"start\" x=\"393.012\" y=\"-618.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 0.8</text>\n",
       "<text text-anchor=\"start\" x=\"423.486\" y=\"-604.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"start\" x=\"414.155\" y=\"-590.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 147</text>\n",
       "<text text-anchor=\"start\" x=\"400.138\" y=\"-576.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [49, 49, 49]</text>\n",
       "<text text-anchor=\"start\" x=\"415.328\" y=\"-562.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M429.784,-513C429.784,-513 333.971,-513 333.971,-513 327.971,-513 321.971,-507 321.971,-501 321.971,-501 321.971,-461 321.971,-461 321.971,-455 327.971,-449 333.971,-449 333.971,-449 429.784,-449 429.784,-449 435.784,-449 441.784,-455 441.784,-461 441.784,-461 441.784,-501 441.784,-501 441.784,-507 435.784,-513 429.784,-513\"/>\n",
       "<text text-anchor=\"start\" x=\"353.272\" y=\"-497.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"340.048\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 49</text>\n",
       "<text text-anchor=\"start\" x=\"329.924\" y=\"-469.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [49, 0, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"337.328\" y=\"-455.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M433.252,-555.769C425.515,-544.66 417.053,-532.509 409.27,-521.333\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"412.061,-519.216 403.474,-513.01 406.317,-523.216 412.061,-519.216\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.07\" y=\"-533.419\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M605.396,-520C605.396,-520 472.359,-520 472.359,-520 466.359,-520 460.359,-514 460.359,-508 460.359,-508 460.359,-454 460.359,-454 460.359,-448 466.359,-442 472.359,-442 472.359,-442 605.396,-442 605.396,-442 611.396,-442 617.396,-448 617.396,-454 617.396,-454 617.396,-508 617.396,-508 617.396,-514 611.396,-520 605.396,-520\"/>\n",
       "<text text-anchor=\"start\" x=\"468.119\" y=\"-504.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\n",
       "<text text-anchor=\"start\" x=\"510.272\" y=\"-490.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"497.048\" y=\"-476.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 98</text>\n",
       "<text text-anchor=\"start\" x=\"483.031\" y=\"-462.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 49]</text>\n",
       "<text text-anchor=\"start\" x=\"485\" y=\"-448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M486.844,-555.769C493.072,-546.939 499.765,-537.451 506.207,-528.318\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"509.129,-530.248 512.033,-520.058 503.409,-526.213 509.129,-530.248\"/>\n",
       "<text text-anchor=\"middle\" x=\"516.289\" y=\"-540.494\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.894118\" stroke=\"black\" d=\"M493.357,-406C493.357,-406 354.398,-406 354.398,-406 348.398,-406 342.398,-400 342.398,-394 342.398,-394 342.398,-340 342.398,-340 342.398,-334 348.398,-328 354.398,-328 354.398,-328 493.357,-328 493.357,-328 499.357,-328 505.357,-334 505.357,-340 505.357,-340 505.357,-394 505.357,-394 505.357,-400 499.357,-406 493.357,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"350.388\" y=\"-390.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\n",
       "<text text-anchor=\"start\" x=\"387.486\" y=\"-376.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.171</text>\n",
       "<text text-anchor=\"start\" x=\"382.048\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 53</text>\n",
       "<text text-anchor=\"start\" x=\"371.924\" y=\"-348.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 48, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"370\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M499.623,-441.769C490.186,-432.579 480.017,-422.676 470.289,-413.201\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"472.561,-410.528 462.955,-406.058 467.677,-415.543 472.561,-410.528\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.976471\" stroke=\"black\" d=\"M723.357,-406C723.357,-406 584.398,-406 584.398,-406 578.398,-406 572.398,-400 572.398,-394 572.398,-394 572.398,-340 572.398,-340 572.398,-334 578.398,-328 584.398,-328 584.398,-328 723.357,-328 723.357,-328 729.357,-328 735.357,-334 735.357,-340 735.357,-340 735.357,-394 735.357,-394 735.357,-400 729.357,-406 723.357,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"580.388\" y=\"-390.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.85</text>\n",
       "<text text-anchor=\"start\" x=\"617.486\" y=\"-376.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n",
       "<text text-anchor=\"start\" x=\"612.048\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n",
       "<text text-anchor=\"start\" x=\"601.924\" y=\"-348.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 44]</text>\n",
       "<text text-anchor=\"start\" x=\"604.276\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>2&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M578.132,-441.769C587.569,-432.579 597.737,-422.676 607.466,-413.201\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"610.078,-415.543 614.8,-406.058 605.194,-410.528 610.078,-415.543\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.976471\" stroke=\"black\" d=\"M265.396,-292C265.396,-292 132.359,-292 132.359,-292 126.359,-292 120.359,-286 120.359,-280 120.359,-280 120.359,-226 120.359,-226 120.359,-220 126.359,-214 132.359,-214 132.359,-214 265.396,-214 265.396,-214 271.396,-214 277.396,-220 277.396,-226 277.396,-226 277.396,-280 277.396,-280 277.396,-286 271.396,-292 265.396,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"128.119\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\n",
       "<text text-anchor=\"start\" x=\"162.486\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.042</text>\n",
       "<text text-anchor=\"start\" x=\"157.048\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 47</text>\n",
       "<text text-anchor=\"start\" x=\"146.924\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 46, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"145\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.389,-327.926C327.191,-317.872 305.262,-306.956 284.611,-296.676\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"286.049,-293.482 275.537,-292.159 282.929,-299.749 286.049,-293.482\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M490.396,-292C490.396,-292 357.359,-292 357.359,-292 351.359,-292 345.359,-286 345.359,-280 345.359,-280 345.359,-226 345.359,-226 345.359,-220 351.359,-214 357.359,-214 357.359,-214 490.396,-214 490.396,-214 496.396,-214 502.396,-220 502.396,-226 502.396,-226 502.396,-280 502.396,-280 502.396,-286 496.396,-292 490.396,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"353.119\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.55</text>\n",
       "<text text-anchor=\"start\" x=\"387.486\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"385.941\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"375.817\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"374.276\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M423.877,-327.769C423.877,-319.57 423.877,-310.803 423.877,-302.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"427.378,-302.058 423.877,-292.058 420.378,-302.059 427.378,-302.058\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M111.633,-171C111.633,-171 12.1223,-171 12.1223,-171 6.12232,-171 0.122316,-165 0.122316,-159 0.122316,-159 0.122316,-119 0.122316,-119 0.122316,-113 6.12232,-107 12.1223,-107 12.1223,-107 111.633,-107 111.633,-107 117.633,-107 123.633,-113 123.633,-119 123.633,-119 123.633,-159 123.633,-159 123.633,-165 117.633,-171 111.633,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"33.2725\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"20.0483\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"start\" x=\"9.92432\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 46, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.113,-213.769C137.724,-202.006 121.908,-189.076 107.591,-177.371\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.767,-174.63 99.8094,-171.01 105.336,-180.049 109.767,-174.63\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M244.581,-171C244.581,-171 153.174,-171 153.174,-171 147.174,-171 141.174,-165 141.174,-159 141.174,-159 141.174,-119 141.174,-119 141.174,-113 147.174,-107 153.174,-107 153.174,-107 244.581,-107 244.581,-107 250.581,-107 256.581,-113 256.581,-119 256.581,-119 256.581,-159 256.581,-159 256.581,-165 250.581,-171 244.581,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"170.272\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"160.941\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"150.817\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"149.276\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.877,-213.769C198.877,-203.313 198.877,-191.935 198.877,-181.315\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.378,-181.01 198.877,-171.01 195.378,-181.01 202.378,-181.01\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M377.581,-171C377.581,-171 286.174,-171 286.174,-171 280.174,-171 274.174,-165 274.174,-159 274.174,-159 274.174,-119 274.174,-119 274.174,-113 280.174,-107 286.174,-107 286.174,-107 377.581,-107 377.581,-107 383.581,-107 389.581,-113 389.581,-119 389.581,-119 389.581,-159 389.581,-159 389.581,-165 383.581,-171 377.581,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"303.272\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"293.941\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"283.817\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n",
       "<text text-anchor=\"start\" x=\"282.276\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M392.474,-213.769C383.258,-202.551 373.171,-190.271 363.917,-179.005\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.402,-176.516 357.35,-171.01 360.993,-180.959 366.402,-176.516\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M561.967,-178C561.967,-178 419.788,-178 419.788,-178 413.788,-178 407.788,-172 407.788,-166 407.788,-166 407.788,-112 407.788,-112 407.788,-106 413.788,-100 419.788,-100 419.788,-100 561.967,-100 561.967,-100 567.967,-100 573.967,-106 573.967,-112 573.967,-112 573.967,-166 573.967,-166 573.967,-172 567.967,-178 561.967,-178\"/>\n",
       "<text text-anchor=\"start\" x=\"415.833\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 6.95</text>\n",
       "<text text-anchor=\"start\" x=\"454.486\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"452.941\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"442.817\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"437\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446.748,-213.769C451.922,-205.119 457.474,-195.838 462.835,-186.877\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"465.98,-188.437 468.11,-178.058 459.973,-184.843 465.98,-188.437\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M471.633,-64C471.633,-64 372.122,-64 372.122,-64 366.122,-64 360.122,-58 360.122,-52 360.122,-52 360.122,-12 360.122,-12 360.122,-6 366.122,-0 372.122,-0 372.122,-0 471.633,-0 471.633,-0 477.633,-0 483.633,-6 483.633,-12 483.633,-12 483.633,-52 483.633,-52 483.633,-58 477.633,-64 471.633,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"393.272\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"383.941\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"373.817\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"368\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M465.772,-99.7956C459.932,-90.9084 453.703,-81.4296 447.827,-72.4883\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"450.743,-70.5521 442.326,-64.1172 444.893,-74.3964 450.743,-70.5521\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M604.581,-64C604.581,-64 513.174,-64 513.174,-64 507.174,-64 501.174,-58 501.174,-52 501.174,-52 501.174,-12 501.174,-12 501.174,-6 507.174,-0 513.174,-0 513.174,-0 604.581,-0 604.581,-0 610.581,-0 616.581,-6 616.581,-12 616.581,-12 616.581,-52 616.581,-52 616.581,-58 610.581,-64 604.581,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"530.272\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"520.941\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"510.817\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"509.276\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M515.619,-99.7956C521.316,-91 527.387,-81.625 533.125,-72.765\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"536.227,-74.4133 538.725,-64.1172 530.352,-70.6082 536.227,-74.4133\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M724.967,-292C724.967,-292 582.788,-292 582.788,-292 576.788,-292 570.788,-286 570.788,-280 570.788,-280 570.788,-226 570.788,-226 570.788,-220 576.788,-214 582.788,-214 582.788,-214 724.967,-214 724.967,-214 730.967,-214 736.967,-220 736.967,-226 736.967,-226 736.967,-280 736.967,-280 736.967,-286 730.967,-292 724.967,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"578.833\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 5.95</text>\n",
       "<text text-anchor=\"start\" x=\"617.486\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"615.941\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"605.817\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"604.276\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M653.877,-327.769C653.877,-319.57 653.877,-310.803 653.877,-302.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"657.378,-302.058 653.877,-292.058 650.378,-302.059 657.378,-302.058\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M862.784,-285C862.784,-285 766.971,-285 766.971,-285 760.971,-285 754.971,-279 754.971,-273 754.971,-273 754.971,-233 754.971,-233 754.971,-227 760.971,-221 766.971,-221 766.971,-221 862.784,-221 862.784,-221 868.784,-221 874.784,-227 874.784,-233 874.784,-233 874.784,-273 874.784,-273 874.784,-279 868.784,-285 862.784,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"786.272\" y=\"-269.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"773.048\" y=\"-255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n",
       "<text text-anchor=\"start\" x=\"762.924\" y=\"-241.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 42]</text>\n",
       "<text text-anchor=\"start\" x=\"765.276\" y=\"-227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>12&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M708.834,-327.769C726.057,-315.788 745.02,-302.597 762.089,-290.722\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"764.09,-293.594 770.301,-285.01 760.093,-287.848 764.09,-293.594\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M703.633,-171C703.633,-171 604.122,-171 604.122,-171 598.122,-171 592.122,-165 592.122,-159 592.122,-159 592.122,-119 592.122,-119 592.122,-113 598.122,-107 604.122,-107 604.122,-107 703.633,-107 703.633,-107 709.633,-107 715.633,-113 715.633,-119 715.633,-119 715.633,-159 715.633,-159 715.633,-165 709.633,-171 703.633,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"625.272\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"615.941\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"605.817\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"600\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M653.877,-213.769C653.877,-203.313 653.877,-191.935 653.877,-181.315\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"657.378,-181.01 653.877,-171.01 650.378,-181.01 657.378,-181.01\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M836.581,-171C836.581,-171 745.174,-171 745.174,-171 739.174,-171 733.174,-165 733.174,-159 733.174,-159 733.174,-119 733.174,-119 733.174,-113 739.174,-107 745.174,-107 745.174,-107 836.581,-107 836.581,-107 842.581,-107 848.581,-113 848.581,-119 848.581,-119 848.581,-159 848.581,-159 848.581,-165 842.581,-171 836.581,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"762.272\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"752.941\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"742.817\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"741.276\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M700.642,-213.769C715.031,-202.006 730.847,-189.076 745.164,-177.371\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"747.419,-180.049 752.946,-171.01 742.988,-174.63 747.419,-180.049\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x181df1e210>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the tree\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing good features is one of your most important jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What Makes a Good Feature? - Machine Learning Recipes\n",
    "\n",
    "Classifiers are only as good as the features you provide. Coming up with good features is one of your most important jobs in machine learning. But, what makes a good feature and how can you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([   1.,    5.,   16.,   46.,   98.,  131.,   98.,   64.,   36.,    5.]),\n",
       "  array([  22.,   24.,  112.,  166.,  212.,  209.,  137.,   75.,   38.,    5.])],\n",
       " array([ 14.24328627,  16.6777133 ,  19.11214034,  21.54656738,\n",
       "         23.98099442,  26.41542145,  28.84984849,  31.28427553,\n",
       "         33.71870257,  36.1531296 ,  38.58755664]),\n",
       " <a list of 2 Lists of Patches objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/hd7SRh7OdcTigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e88e4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a population of dogs: greyhounds and labradors\n",
    "greyhounds = 500\n",
    "labs = 500\n",
    "\n",
    "# Height on average +- 4 distributed normally\n",
    "grey_height = 28 + 4 * np.random.randn(greyhounds)\n",
    "lab_height = 24 + 4 * np.random.randn(labs)\n",
    "\n",
    "plt.hist([grey_height, lab_height], stacked=True, color=[\"r\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features capture different type of information\n",
    "\n",
    "IDEAL FEATURES are:\n",
    "- Informative\n",
    "- Independent\n",
    "- Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Let’s Write a Pipeline - Machine Learning Recipes\n",
    "\n",
    "Example: classify email to be SPAM or not\n",
    "EMAIL -> CLASSIFIER -> SPAM?\n",
    "\n",
    "DATASET\n",
    "- Email text\n",
    "- Label: Spam or Not spam\n",
    "\n",
    "You are training a model but before you put it into production there is a question you need to answer first:\n",
    "- How accurate will it be when you use it to classify emails that weren't in your training data?\n",
    "- As best as we can, we want to verify our models work well before we deploy them\n",
    "\n",
    "Approaches to do so:\n",
    "- Partition our data into two parts: TRAIN and TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data # features x\n",
    "y = iris.target # labels y\n",
    "# f(x) = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 1, 2, 2, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0, 1,\n",
       "       1, 0, 0, 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 2, 1, 1, 1,\n",
       "       2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 2, 0, 2, 0, 2, 0, 1, 2, 0, 1, 2, 0,\n",
       "       2, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is over 90%. If you try this on your own, it might be a little bit different because of some randomness in how the TRAIN / TEST data is partitioned!\n",
    "\n",
    "We can use a different classifier to accomplish the same task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAKE-AWAY\n",
    "- There are many different types of classifier and, at a high level, they have a similar interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GREAT TOOL\n",
    "\n",
    "http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Writing Our First Classifier - Machine Learning Recipes\n",
    "\n",
    "Write our own classifier: scrappy version of KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def euc(a, b):\n",
    "    return distance.euclidean(a, b)\n",
    "\n",
    "class ScrappyKNN():\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # store data\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            # label = random.choice(self.y_train) # Random: accuracy around 33%\n",
    "            label = self.closest(row) # over 90% now\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    \n",
    "    def closest(self, row):\n",
    "        best_dist = euc(row, self.X_train[0])\n",
    "        best_index = 0\n",
    "        for i in range(1, len(self.X_train)):\n",
    "            dist = euc(row, self.X_train[i])\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_index = i\n",
    "        return self.y_train[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ScrappyKNN()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAKE-AWAYS for the K-Nearest Neighbors:\n",
    "\n",
    "PROS\n",
    "- Relatively simple\n",
    "\n",
    "CONS\n",
    "- Computationally intensive\n",
    "- Hard to represent relationships between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train an Image Classifier with TensorFlow for Poets - Machine Learning Recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train an image classifier with just a directory of images\n",
    "\n",
    "Codelab: TensorFlow for Poets, great way to learn about and work with image classification.\n",
    "Also, thanks to TheCoinTosser for the detailed notebook regarding this recipe - https://github.com/TheCoinTosser/MachineLearningGoogleSeries\n",
    "\n",
    "TensorFlow for Poets\n",
    "- High level code\n",
    "- Powerful classifier: better that what you could have written a few years ago\n",
    "\n",
    "TensorFlow is especially useful for working with a branch of machine learning called deep learning. In Deep Learning, you don't need to extract features manually. That is why it is so useful in image classification tasks since it is very hard to extract image features by hand. The classifier used in deep learning is called Neural Network. A Neural Network is just another type of classifier, like the nearest neighbor one we wrote last time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Step 1 - Download and extract the flower training images\n",
    "- Download the flower training data: http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "- Untar the file: $ tar xvzf flower_photos.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE.txt  \u001b[34mdaisy\u001b[m\u001b[m/       \u001b[34mdandelion\u001b[m\u001b[m/   \u001b[34mroses\u001b[m\u001b[m/       \u001b[34msunflowers\u001b[m\u001b[m/  \u001b[34mtulips\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls flower_photos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Learn:\n",
    "- High level ML library on top of TensorFlow\n",
    "- Similar to scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, cross_validation\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# Load dataset\n",
    "iris = learn.datasets.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.DNNClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/88/1fj6xym51msf2jxcjcgd824r0000gp/T/tmpAKT4y1\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c14c7c550>, '_model_dir': '/var/folders/88/1fj6xym51msf2jxcjcgd824r0000gp/T/tmpAKT4y1', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively\n",
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
    "classifier = learn.DNNClassifier(hidden_units=[10, 20, 10], feature_columns=feature_columns, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float64, normalizer=None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x1c14c7c610>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float64, normalizer=None),), 'embedding_lr_multipliers': None, 'optimizer': None, 'dropout': None, 'gradient_clip_norm': None, 'activation_fn': <function relu at 0x150e4f29b0>, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-da02303393c2>:2: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-19-da02303393c2>:2: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/88/1fj6xym51msf2jxcjcgd824r0000gp/T/tmpAKT4y1/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.16209, step = 1\n",
      "INFO:tensorflow:global_step/sec: 578.54\n",
      "INFO:tensorflow:loss = 0.227998, step = 101 (0.174 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/88/1fj6xym51msf2jxcjcgd824r0000gp/T/tmpAKT4y1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.100116.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x1c14c7c610>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float64, normalizer=None),), 'embedding_lr_multipliers': None, 'optimizer': None, 'dropout': None, 'gradient_clip_norm': None, 'activation_fn': <function relu at 0x150e4f29b0>, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and predict\n",
    "classifier.fit(x_train, y_train, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/88/1fj6xym51msf2jxcjcgd824r0000gp/T/tmpAKT4y1/model.ckpt-200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = list(classifier.predict(x_test, as_iterable=True))\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.966667\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_test, y_predicted)\n",
    "print \"Accuracy {0:f}\".format(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2 - Download TensorFlow's pre-trained models\n",
    "\n",
    "- cd ml_google/\n",
    "- git clone https://github.com/tensorflow/models.git\n",
    "- $ python models/tutorials/image/imagenet/classify_image.py "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">> Downloading inception-2015-12-05.tgz 100.0%\n",
    "Successfully downloaded inception-2015-12-05.tgz 88931400 bytes.\n",
    "2017-11-13 12:54:53.673484: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
    "2017-11-13 12:54:55.042998: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
    "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.89107)\n",
    "indri, indris, Indri indri, Indri brevicaudatus (score = 0.00779)\n",
    "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00296)\n",
    "custard apple (score = 0.00147)\n",
    "earthstar (score = 0.00117)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy retrain.py as the codelab code is not able to be downloaded at this time:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mmodels\u001b[m\u001b[m/     retrain.py\r\n"
     ]
    }
   ],
   "source": [
    "ls ml_google/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ python retrain.py \\\n",
    "--bottleneck_dir=bottlenecks \\\n",
    "--how_many_training_steps 500 \\\n",
    "--model_dir=models/ \\\n",
    "--output_graph=trained_images_outputs/retrained_graph.pb \\\n",
    "--output_labels=trained_images_outputs/retrained_labels.txt \\\n",
    "--image_dir ../flower_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script takes about 20 minutes to train the classifier, which is not a long time.\n",
    "\n",
    "Under the hood, the script is not training a classifier from scratch. Instead it's starting with an existing classifier called Inception\n",
    "\n",
    "Inception\n",
    "- One of Google's best image classifiers\n",
    "- Open source\n",
    "- Trained on 1.2 million images\n",
    "- Training took 2 weeks on a fast desktop with eight GPUs\n",
    "\n",
    "In this codelab, we will begin with Inception and then use a technique called retraining to adjust it to work with our images. This let us reuse some the parameters Inception has previously learned so we can create a new high accurary classifier with far less training data.\n",
    "\n",
    "Retraining (also known as Transfer Learning):\n",
    "- Saves a lot of time\n",
    "- Leverages prior work\n",
    "\n",
    "One we have a trained classifier, we can try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File name: daisy_test_1.jpg\n",
      "daisy (score = 0.96834)\n",
      "sunflowers (score = 0.02731)\n",
      "dandelion (score = 0.00276)\n",
      "tulips (score = 0.00148)\n",
      "roses (score = 0.00010)\n",
      "\n",
      "File name: daisy_test_2.jpg\n",
      "daisy (score = 0.96587)\n",
      "sunflowers (score = 0.02784)\n",
      "dandelion (score = 0.00523)\n",
      "tulips (score = 0.00102)\n",
      "roses (score = 0.00004)\n",
      "\n",
      "File name: daisy_test_3.jpg\n",
      "daisy (score = 0.36597)\n",
      "sunflowers (score = 0.26666)\n",
      "tulips (score = 0.14828)\n",
      "roses (score = 0.13861)\n",
      "dandelion (score = 0.08048)\n",
      "\n",
      "File name: daisy_test_4.jpg\n",
      "roses (score = 0.50272)\n",
      "dandelion (score = 0.15695)\n",
      "tulips (score = 0.15310)\n",
      "daisy (score = 0.13058)\n",
      "sunflowers (score = 0.05664)\n",
      "\n",
      "File name: dandelion_test_1.jpg\n",
      "dandelion (score = 0.98852)\n",
      "sunflowers (score = 0.00402)\n",
      "daisy (score = 0.00328)\n",
      "tulips (score = 0.00293)\n",
      "roses (score = 0.00124)\n",
      "\n",
      "File name: dandelion_test_2.jpg\n",
      "dandelion (score = 0.85607)\n",
      "daisy (score = 0.07476)\n",
      "sunflowers (score = 0.03042)\n",
      "tulips (score = 0.03035)\n",
      "roses (score = 0.00839)\n",
      "\n",
      "File name: dandelion_test_3.jpg\n",
      "dandelion (score = 0.38816)\n",
      "roses (score = 0.22766)\n",
      "daisy (score = 0.22188)\n",
      "sunflowers (score = 0.12237)\n",
      "tulips (score = 0.03994)\n",
      "\n",
      "File name: dandelion_test_4.jpg\n",
      "dandelion (score = 0.98880)\n",
      "sunflowers (score = 0.00583)\n",
      "roses (score = 0.00201)\n",
      "tulips (score = 0.00191)\n",
      "daisy (score = 0.00145)\n",
      "\n",
      "File name: rose_test_1.jpg\n",
      "roses (score = 0.96780)\n",
      "tulips (score = 0.01435)\n",
      "sunflowers (score = 0.00797)\n",
      "dandelion (score = 0.00613)\n",
      "daisy (score = 0.00375)\n",
      "\n",
      "File name: rose_test_2.jpg\n",
      "roses (score = 0.95247)\n",
      "tulips (score = 0.04012)\n",
      "daisy (score = 0.00346)\n",
      "sunflowers (score = 0.00307)\n",
      "dandelion (score = 0.00088)\n",
      "\n",
      "File name: rose_test_3.jpg\n",
      "roses (score = 0.65795)\n",
      "daisy (score = 0.11518)\n",
      "tulips (score = 0.11378)\n",
      "sunflowers (score = 0.07082)\n",
      "dandelion (score = 0.04226)\n",
      "\n",
      "File name: rose_test_4.jpg\n",
      "roses (score = 0.52348)\n",
      "tulips (score = 0.32871)\n",
      "sunflowers (score = 0.07646)\n",
      "dandelion (score = 0.06157)\n",
      "daisy (score = 0.00979)\n",
      "\n",
      "File name: sunflower_test_1.jpg\n",
      "sunflowers (score = 0.80697)\n",
      "daisy (score = 0.17271)\n",
      "dandelion (score = 0.00995)\n",
      "tulips (score = 0.00978)\n",
      "roses (score = 0.00059)\n",
      "\n",
      "File name: sunflower_test_2.jpg\n",
      "sunflowers (score = 0.87595)\n",
      "dandelion (score = 0.11304)\n",
      "roses (score = 0.00600)\n",
      "tulips (score = 0.00306)\n",
      "daisy (score = 0.00196)\n",
      "\n",
      "File name: sunflower_test_3.jpg\n",
      "sunflowers (score = 0.49500)\n",
      "tulips (score = 0.28110)\n",
      "roses (score = 0.16289)\n",
      "daisy (score = 0.03960)\n",
      "dandelion (score = 0.02141)\n",
      "\n",
      "File name: sunflower_test_4.jpg\n",
      "sunflowers (score = 0.69516)\n",
      "dandelion (score = 0.12500)\n",
      "tulips (score = 0.11707)\n",
      "roses (score = 0.04516)\n",
      "daisy (score = 0.01762)\n",
      "\n",
      "File name: tulip_test_1.jpg\n",
      "tulips (score = 0.86510)\n",
      "roses (score = 0.12138)\n",
      "sunflowers (score = 0.00562)\n",
      "dandelion (score = 0.00425)\n",
      "daisy (score = 0.00364)\n",
      "\n",
      "File name: tulip_test_2.jpg\n",
      "tulips (score = 0.78024)\n",
      "roses (score = 0.12474)\n",
      "dandelion (score = 0.05754)\n",
      "sunflowers (score = 0.02131)\n",
      "daisy (score = 0.01617)\n",
      "\n",
      "File name: tulip_test_3.jpg\n",
      "tulips (score = 0.76940)\n",
      "dandelion (score = 0.07593)\n",
      "roses (score = 0.07506)\n",
      "daisy (score = 0.04823)\n",
      "sunflowers (score = 0.03139)\n",
      "\n",
      "File name: tulip_test_4.jpg\n",
      "roses (score = 0.90428)\n",
      "tulips (score = 0.05703)\n",
      "sunflowers (score = 0.03388)\n",
      "dandelion (score = 0.00298)\n",
      "daisy (score = 0.00183)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_test_set_folder = 'flower_test_set'\n",
    "\n",
    "for file_name in os.listdir(image_test_set_folder):\n",
    "\n",
    "    # Read in the image_data\n",
    "    image_data = tf.gfile.FastGFile(image_test_set_folder + '/' + file_name, 'rb').read()\n",
    "\n",
    "    # Loads label file, strips off carriage return\n",
    "    label_lines = [line.rstrip() for line\n",
    "                   in tf.gfile.GFile(\"ml_google/trained_images_outputs/retrained_labels.txt\")]\n",
    "\n",
    "    # Read the new .pb file which represents the new trained model\n",
    "    with tf.gfile.FastGFile(\"ml_google/trained_images_outputs/retrained_graph.pb\", 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "        # Sort to show labels of first prediction in order of confidence\n",
    "        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "\n",
    "        print(\"\\nFile name: %s\" % file_name)\n",
    "        for node_id in top_k:\n",
    "            human_string = label_lines[node_id]\n",
    "            score = predictions[0][node_id]\n",
    "            print('%s (score = %.5f)' % (human_string, score))\n",
    "            if human_string in 'metermaid':\n",
    "                if score * 100 > 75:\n",
    "                    print('%s winner %s' % (score * 100, human_string))\n",
    "                    message = '%s chance %s was seen' % (score * 100, human_string)\n",
    "                    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
