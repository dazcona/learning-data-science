{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning keras with Nathaniel Tucker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook dedicated to follow the awesome serie of keras videos created by Nathaniel Tucker.\n",
    "\n",
    "Tucker's Youtube channel: https://www.youtube.com/channel/UCQTQ0AbOupKNxKKY-_x46OQ\n",
    "\n",
    "Tucker's Github repo: https://github.com/knathanieltucker/a-bit-of-deep-learning-and-keras/\n",
    "\n",
    "I can't thank him enough for his videos and his reponses to my questions on them. This material is just me running his notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.keras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction and Installation\n",
    "\n",
    "## Keras: Deep Learning library for Theano and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level neural networks API, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "\n",
    "- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "- Runs seamlessly on CPU and GPU.\n",
    "\n",
    "### Guiding principles\n",
    "\n",
    "- User friendliness. Keras is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.\n",
    "- Modularity. A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.\n",
    "- Easy extensibility. New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.\n",
    "- Work with Python. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.\n",
    "\n",
    "\n",
    "### Getting started\n",
    "\n",
    "The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API, which allows to build arbitrary graphs of layers.\n",
    "\n",
    "We will only very breifly touch on the Sequential model because the functional model is much more expressive and frankly easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 2us/step\n",
      "65536/57026 [==================================] - 0s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# quickly grab the data\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "404 samples with 13 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102, 13), (102,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct your model with a couple of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is created, you will need to compile it (and specify some opitonal params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer='adam',\n",
    "              metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You fit your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "404/404 [==============================] - 0s 11us/step - loss: 173.9312 - mean_absolute_percentage_error: 44.8552\n",
      "Epoch 2/20\n",
      "404/404 [==============================] - 0s 7us/step - loss: 164.6236 - mean_absolute_percentage_error: 44.1456\n",
      "Epoch 3/20\n",
      "404/404 [==============================] - 0s 7us/step - loss: 156.3709 - mean_absolute_percentage_error: 43.6080\n",
      "Epoch 4/20\n",
      "404/404 [==============================] - 0s 7us/step - loss: 149.1620 - mean_absolute_percentage_error: 43.2081\n",
      "Epoch 5/20\n",
      "404/404 [==============================] - 0s 11us/step - loss: 142.9950 - mean_absolute_percentage_error: 43.0268\n",
      "Epoch 6/20\n",
      "404/404 [==============================] - 0s 9us/step - loss: 137.8471 - mean_absolute_percentage_error: 43.1045\n",
      "Epoch 7/20\n",
      "404/404 [==============================] - 0s 5us/step - loss: 133.6082 - mean_absolute_percentage_error: 43.2856\n",
      "Epoch 8/20\n",
      "404/404 [==============================] - 0s 10us/step - loss: 130.2039 - mean_absolute_percentage_error: 43.5497\n",
      "Epoch 9/20\n",
      "404/404 [==============================] - 0s 11us/step - loss: 127.5496 - mean_absolute_percentage_error: 43.9216\n",
      "Epoch 10/20\n",
      "404/404 [==============================] - 0s 7us/step - loss: 125.5404 - mean_absolute_percentage_error: 44.3604\n",
      "Epoch 11/20\n",
      "404/404 [==============================] - 0s 16us/step - loss: 124.1100 - mean_absolute_percentage_error: 44.8329\n",
      "Epoch 12/20\n",
      "404/404 [==============================] - 0s 8us/step - loss: 123.1079 - mean_absolute_percentage_error: 45.2711\n",
      "Epoch 13/20\n",
      "404/404 [==============================] - 0s 8us/step - loss: 122.4204 - mean_absolute_percentage_error: 45.7267\n",
      "Epoch 14/20\n",
      "404/404 [==============================] - 0s 8us/step - loss: 121.9250 - mean_absolute_percentage_error: 46.1489\n",
      "Epoch 15/20\n",
      "404/404 [==============================] - 0s 8us/step - loss: 121.5194 - mean_absolute_percentage_error: 46.5337\n",
      "Epoch 16/20\n",
      "404/404 [==============================] - 0s 8us/step - loss: 121.1067 - mean_absolute_percentage_error: 46.8253\n",
      "Epoch 17/20\n",
      "404/404 [==============================] - 0s 5us/step - loss: 120.6100 - mean_absolute_percentage_error: 47.0111\n",
      "Epoch 18/20\n",
      "404/404 [==============================] - 0s 7us/step - loss: 119.9812 - mean_absolute_percentage_error: 47.0935\n",
      "Epoch 19/20\n",
      "404/404 [==============================] - 0s 5us/step - loss: 119.1862 - mean_absolute_percentage_error: 47.0645\n",
      "Epoch 20/20\n",
      "404/404 [==============================] - 0s 11us/step - loss: 118.2118 - mean_absolute_percentage_error: 46.9235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a182f00d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=404)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you fit your model, the loss goes down i.e. you are better able to predict what's gonna happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check by evaluating on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "102/102 [==============================] - 0s 18us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[137.73875427246094, 54.496906280517578]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this, you can always use your model to make predictions in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices = model.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.46040154],\n",
       "       [ 25.13182068],\n",
       "       [ 18.57298088],\n",
       "       [ 22.7492218 ],\n",
       "       [ 19.2775898 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Datasets\n",
    "\n",
    "## Boston housing price regression dataset\n",
    "\n",
    "Dataset taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
    "\n",
    "Samples contain 13 attributes of houses at different locations around the Boston suburbs in the late 1970s. Targets are the median values of the houses at a location (in k$).\n",
    "\n",
    "This is the only REGRESSION dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is the first time that you are loading the dataset, it will download the data for you and store it in ~/.keras/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston_housing.get_file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1.23247,    0.     ,    8.14   ,    0.     ,    0.538  ,\n",
       "           6.142  ,   91.7    ,    3.9769 ,    4.     ,  307.     ,\n",
       "          21.     ,  396.9    ,   18.72   ]), 15.199999999999999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 small image classification\n",
    "\n",
    "Dataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10.load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # first image\n",
    "img = x_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage object at 0x181f827dd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure object at 0x181f827d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Example %d. Label: %d' % (i, y_test[i]))\n",
    "plt.imshow(img, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR100 small image classification\n",
    "\n",
    "Dataset of 50,000 32x32 color training images, labeled over 100 categories, and 10,000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST database of handwritten digits\n",
    "\n",
    "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "img = x_test[i]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage object at 0x18282f7090>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOfxmiXL4zRLl8Jsl6v8BLRKkvKOqeIgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure object at 0x18282f70d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Example %d. Label: %d' % (i, y_test[i]))\n",
    "plt.imshow(img, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two are going to be Natural Language Processing datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Movie reviews sentiment classification\n",
    "\n",
    "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
    "\n",
    "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 3s 0us/step\n",
      "17473536/17464789 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n",
    "                                                      num_words=None,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2,\n",
    "                                                      index_from=3)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the second shape is sort of None, it means it can be varied!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it does not print the array items one per line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12], 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the data is already tokenized for us, we will talk more about this on the Preprocessing section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters newswire topics classification\n",
    "\n",
    "Dataset of 11,228 newswires from Reuters, labeled over 46 topics. As with the IMDB dataset, each wire is encoded as a sequence of word indexes (same conventions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 0us/step\n",
      "2121728/2110848 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.pkl\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12], 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets stored in ~/.keras/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 393808\r\n",
      "-rw-r--r--   1 dazconap  staff      57026 Nov 13 15:04 boston_housing.npz\r\n",
      "drwxr-xr-x  10 dazconap  staff        340 Jun  4  2009 \u001b[34mcifar-10-batches-py\u001b[m\u001b[m/\r\n",
      "-rw-r--r--   1 dazconap  staff  170498071 Nov 20 11:46 cifar-10-batches-py.tar.gz\r\n",
      "-rw-r--r--   1 dazconap  staff   17464789 Nov 20 11:47 imdb_full.pkl\r\n",
      "-rw-r--r--   1 dazconap  staff   11490434 Nov 20 11:47 mnist.npz\r\n",
      "-rw-r--r--   1 dazconap  staff    2110848 Nov 20 11:49 reuters.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls -l ~/.keras/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
